import json
import copy
from typing import Dict, Tuple, Optional, Any, List
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from config import LLM_TEMP_HIGH, LLM_TEMP_LOW, COLLECTION_MENTORS # LLM ve RAG objelerini config'den al
from rag_manager import retrieve_context # RAG sorgulama fonksiyonu
from prompt import QUESTION_PROMPT

# --- YARDIMCI FOKNSÄ°YONLAR ---

def _topk_separation_ok(
    metrics: Dict[str, int],
    k: int = 5,
    sep_gap: int = 12
) -> Tuple[bool, List[Tuple[str, int]]]:
    """
    SkorlarÄ± azalan sÄ±rala ve ilk k metrik iÃ§in (k-1) ardÄ±ÅŸÄ±k gap >= sep_gap mi kontrol et.
    DÃ¶nÃ¼ÅŸ: (True/False, top_k_list)
    """
    if not metrics or len(metrics) < k:
        return (False, [])
    top = sorted(metrics.items(), key=lambda kv: kv[1], reverse=True)[:k]
    
    # ArdÄ±ÅŸÄ±k boÅŸluklarÄ±n hepsi eÅŸikten bÃ¼yÃ¼k/eÅŸit mi?
    gaps_ok = all(top[i][1] - top[i + 1][1] >= sep_gap for i in range(k - 1))
    
    return (gaps_ok, top)

def retrieve_mentor_context(metrics: Dict[str, int]) -> str:
    """RAG'dan mentor baÄŸlamÄ±nÄ± Ã§eken yardÄ±mcÄ± fonksiyon (soru Ã¼retimine ilham vermesi iÃ§in)."""
    # En yÃ¼ksek ve en dÃ¼ÅŸÃ¼k metrikleri alarak LLM'i odakla
    sorted_metrics = sorted(metrics.items(), key=lambda item: item[1], reverse=True)
    top_and_bottom_metrics = dict(sorted_metrics[:3] + sorted_metrics[-3:])
    rag_query = f"Hangi yetenekler test edilmeli? GÃ¼Ã§lÃ¼/ZayÄ±f Metrikler: {top_and_bottom_metrics}"
    
    return retrieve_context(COLLECTION_MENTORS, rag_query, n_results=2)


# --- SORGULAMA VE ANALÄ°Z FONKSÄ°YONLARI (LLM Ä°LE Ä°LETÄ°ÅÄ°M) ---

def get_next_question(metrics: Dict[str, int]) -> Tuple[Optional[str], Optional[str]]:
    try:
        rag_context = retrieve_mentor_context(metrics)

        QUESTION_PROMPT = ChatPromptTemplate.from_template("""
            # ROLE: Expert Career Evaluator
            # GOAL: Verify the accuracy of the user's current skill scores.

            # CONTEXT:
            Current Metrics (Scores 0-100): {metrics}
            RAG Mentor Context (for inspiration): {rag_context}

            # INSTRUCTIONS:
            1. Select ONE metric from the list that would be most revealing to verify (e.g., the highest, lowest, or a key skill).
            2. Formulate ONE open-ended, engaging, and behavior-based question to thoroughly test that chosen metric.
            3. Your response MUST adhere to the REQUIRED FORMAT.

            # REQUIRED FORMAT (Return ONLY this text block):
            Metric Tested: [The exact full name of the metric you chose, e.g., 'Strategic Intelligence']
            Question: [Your behavioral question text]
        """)

        chain = QUESTION_PROMPT | LLM_TEMP_HIGH | StrOutputParser()
        raw = chain.invoke({
            "metrics": json.dumps(metrics, indent=2, ensure_ascii=False),
            "rag_context": rag_context
        })

        if not raw:
            return (None, None)

        # Basit ama saÄŸlam ayrÄ±ÅŸtÄ±rma
        text = raw.strip()
        # Ã–nce beklenen etiketlere gÃ¶re bÃ¶l
        if "Metric Tested:" in text and "Question:" in text:
            try:
                metric_tested = text.split("Metric Tested:", 1)[1].split("\n", 1)[0].strip()
                question_text = text.split("Question:", 1)[1].strip()
                # GÃ¼venlik: boÅŸsa None
                if not metric_tested or not question_text:
                    return (None, None)
                return (question_text, metric_tested)
            except Exception:
                return (None, None)

        # Beklenen formatta deÄŸilse, fallback: tek satÄ±r soru gibi davranma
        return (None, None)

    except Exception as e:
        print(f"âŒ get_next_question hata: {e}")
        return (None, None)


def get_update_instruction(metrics: Dict[str, int], question: str, user_answer: str) -> Optional[Dict]:
    """Analiz LLM'i: CevabÄ± analiz eder ve metrik gÃ¼ncelleme talimatÄ± verir (JSON)."""
    
    # (Kod aynÄ± kalÄ±r)
    # ...
    pass # Ã–nceki cevapta mutabÄ±k kaldÄ±ÄŸÄ±mÄ±z get_update_instruction iÃ§eriÄŸi buraya gelecek


# --- METRÄ°K GÃœNCELLEME VE DURDURMA FONKSÄ°YONLARI ---

def _update_metrics(current_metrics: Dict[str, int], instruction: Dict) -> Tuple[Dict[str, int], Dict[str, int]]:
    """
    Metrikleri gÃ¼venli bir ÅŸekilde gÃ¼nceller ve gÃ¼ncellenen miktarlarÄ± iÃ§eren bir 'delta' sÃ¶zlÃ¼ÄŸÃ¼ dÃ¶ndÃ¼rÃ¼r.
    """
    metric_name = instruction.get('metric_to_update') 
    direction = instruction.get('direction')
    amount = instruction.get('amount', 0)
    deltas = {}

    # Metrikte bir deÄŸiÅŸiklik yapÄ±lacaksa
    if metric_name in current_metrics and direction in ['increase', 'decrease'] and amount > 0:
        
        before_value = current_metrics[metric_name]
        
        if direction == 'increase':
            delta = amount
        else: # 'decrease'
            delta = -amount
        
        current_metrics[metric_name] += delta
        current_metrics[metric_name] = max(0, min(100, current_metrics[metric_name])) # SÄ±nÄ±rla
        
        # DeÄŸiÅŸim miktarÄ±nÄ± delta sÃ¶zlÃ¼ÄŸÃ¼ne kaydet (dÃ¶ngÃ¼de kullanÄ±lacak)
        deltas[metric_name] = current_metrics[metric_name] - before_value
        
        # Konsol Ã§Ä±ktÄ±sÄ±
        print("="*60)
        print(f"âœ… Analiz Ã–zeti: {instruction.get('analysis_summary', 'N/A')}")
        print(f"GÃ¼ncellenen Metrik: '{metric_name}'")
        print(f"Ã–nceki DeÄŸer: {before_value} -> Yeni DeÄŸer: {current_metrics[metric_name]} ({direction} {amount})")
        print("="*60)
    elif instruction.get('direction', '').lower() == 'neutral':
        print("\n" + "="*60)
        print(f"â„¹ï¸ Analiz Ã–zeti: {instruction.get('analysis_summary', 'N/A')}")
        print("Metrik gÃ¼ncellenmedi (NÃ¶tr Karar).")
        print("="*60)
        
    return current_metrics, deltas


# --- 4. ANA DÃ–NGÃœ YÃ–NETÄ°CÄ°SÄ° (main_chatbot) ---

def main_chatbot(
    initial_metrics: Dict[str, int],
    max_rounds: int = 10,
    sep_target_k: int = 5,
    sep_gap: int = 12,
    sep_patience: int = 2,
    neutral_patience: int = 2,
    min_net_change_threshold: int = 2
) -> Dict[str, int]:
    
    current = copy.deepcopy(initial_metrics)

    # Streak sayaÃ§larÄ±
    separation_streak = 0
    neutral_streak = 0
    small_change_streak = 0

    print("\n=== DoÄŸrulama DÃ¶ngÃ¼sÃ¼ BaÅŸladÄ± ===")
    print(json.dumps(current, indent=2, ensure_ascii=False))

    for r in range(1, max_rounds + 1):
        print(f"\n--- TUR {r}/{max_rounds} ---")

        # --- DURDURMA KRÄ°TERÄ° KONTROLÃœ (BaÅŸlangÄ±Ã§) ---
        separated, topk_list = _topk_separation_ok(current, k=sep_target_k, sep_gap=sep_gap)
        if separated and separation_streak >= sep_patience:
             topk_str = ", ".join([f"{n}:{s}" for n, s in topk_list])
             print(f"âœ… DUR: Ä°lk {sep_target_k} metrik net biÃ§imde ayrÄ±ÅŸtÄ± (gapâ‰¥{sep_gap}) ve {sep_patience} tur korundu. {topk_str}")
             break

        q_text, tested_metric = get_next_question(current)
        if not q_text:
            print("Model soru Ã¼retemedi, dÃ¶ngÃ¼ bitiyor.")
            break

        user_answer = input(f"Soru: {q_text}\nCevabÄ±nÄ±z: ")
        if user_answer.strip().lower() in {"quit", "exit", "stop"}:
            print("KullanÄ±cÄ± durdurdu.")
            break

        instr = get_update_instruction(current, q_text, user_answer)
        if not instr:
            print("GeÃ§erli talimat alÄ±namadÄ± (JSON). Tur atlandÄ±.")
            continue

        # ğŸ”§ KRÄ°TÄ°K DÃœZELTME: Metrik gÃ¼ncelleme ve delta hesaplama
        old_metrics = copy.deepcopy(current)
        current, deltas = _update_metrics(current, instr) 
        
        # Total deÄŸiÅŸim miktarÄ±nÄ± hesapla
        total_abs_delta = sum(abs(v) for v in deltas.values())

        # --- GÃœNCELLEME VE STREAK YÃ–NETÄ°MÄ° ---

        # 1. Neutral Streak KontrolÃ¼
        if instr.get('direction', '').lower() == 'neutral' or total_abs_delta == 0:
            neutral_streak += 1
            print("ğŸ”¹ DeÄŸiÅŸim yok (neutral veya uygulanamadÄ±).")
        else:
            neutral_streak = 0
            
        # 2. Small Change Streak KontrolÃ¼
        if total_abs_delta < min_net_change_threshold and total_abs_delta > 0:
            small_change_streak += 1
        else:
            small_change_streak = 0

        # 3. AyrÄ±ÅŸma Streak KontrolÃ¼
        if separated:
            separation_streak += 1
            topk_str = ", ".join([f"{n}:{s}" for n, s in topk_list])
            print(f"ğŸ AyrÄ±ÅŸma saÄŸlandÄ± (gapâ‰¥{sep_gap}) [streak={separation_streak}] â†’ {topk_str}")
        else:
            separation_streak = 0
        
        # --- Ä°KÄ°NCÄ°L DURDURMA Ã–LÃ‡ÃœTLERÄ° ---
        if neutral_streak >= neutral_patience:
            print(f"âœ… DUR: Arka arkaya {neutral_streak} tur 'neutral' â€” stabil.")
            break
        if small_change_streak >= 2:
            print(f"âœ… DUR: Ä°ki tur Ã¼st Ã¼ste kÃ¼Ã§Ã¼k deÄŸiÅŸim (<{min_net_change_threshold}).")
            break
        
        # Tur Ã¶zeti
        print("Mevcut metrikler (SÄ±ralÄ±):")
        sorted_output = sorted(current.items(), key=lambda kv: kv[1], reverse=True)
        print(json.dumps(dict(sorted_output), indent=2, ensure_ascii=False))

    print("\n=== DoÄŸrulama DÃ¶ngÃ¼sÃ¼ Bitti ===")
    print(json.dumps(current, indent=2, ensure_ascii=False))
    return current